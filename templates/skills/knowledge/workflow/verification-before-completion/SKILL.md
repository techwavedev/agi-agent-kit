---
name: verification-before-completion
description: Universal verification gate. MANDATORY before any completion claim, success assertion, commit, or PR. Evidence before claims, always.
version: 1.0.0
---

# Verification Before Completion

> Adapted from obra/superpowers — integrated with agi verification scripts.

## Overview

Claiming work is complete without verification is dishonesty, not efficiency.

**Core principle:** Evidence before claims, always.

**Violating the letter of this rule is violating the spirit of this rule.**

---

## The Iron Law

```
NO COMPLETION CLAIMS WITHOUT FRESH VERIFICATION EVIDENCE
```

If you haven't run the verification command in this message, you cannot claim it passes.

---

## The Gate Function

```
BEFORE claiming any status or expressing satisfaction:

1. IDENTIFY: What command proves this claim?
2. RUN: Execute the FULL command (fresh, complete)
3. READ: Full output, check exit code, count failures
4. VERIFY: Does output confirm the claim?
   - If NO: State actual status with evidence
   - If YES: State claim WITH evidence
5. ONLY THEN: Make the claim

Skip any step = unverified, not verified
```

---

## Evidence Requirements

| Claim                 | Requires                        | Not Sufficient                 |
| --------------------- | ------------------------------- | ------------------------------ |
| Tests pass            | Test command output: 0 failures | Previous run, "should pass"    |
| Linter clean          | Linter output: 0 errors         | Partial check, extrapolation   |
| Build succeeds        | Build command: exit 0           | Linter passing, logs look good |
| Bug fixed             | Test original symptom: passes   | Code changed, assumed fixed    |
| Regression test works | Red-green cycle verified        | Test passes once               |
| Agent completed       | VCS diff shows changes          | Agent reports "success"        |
| Requirements met      | Line-by-line checklist          | Tests passing                  |

---

## Integration with Agi Scripts

When available, use the project's verification scripts:

| Verification  | Script             | Command                                                               |
| ------------- | ------------------ | --------------------------------------------------------------------- |
| Full audit    | `checklist.py`     | `python .agent/scripts/checklist.py .`                                |
| Security scan | `security_scan.py` | `python .agent/skills/vulnerability-scanner/scripts/security_scan.py` |
| Lint check    | `lint_runner.py`   | `python .agent/skills/lint-and-validate/scripts/lint_runner.py`       |
| Tests         | `test_runner.py`   | `python .agent/skills/testing-patterns/scripts/test_runner.py`        |
| UX audit      | `ux_audit.py`      | `python .agent/skills/frontend-design/scripts/ux_audit.py`            |

> If no project scripts exist, use the project's native test/build commands.

---

## Red Flags — STOP

If you catch yourself thinking:

- Using "should", "probably", "seems to"
- Expressing satisfaction before verification ("Great!", "Perfect!", "Done!")
- About to commit/push/PR without verification
- Trusting agent success reports without checking
- Relying on partial verification
- Thinking "just this once"
- **ANY wording implying success without having run verification**

---

## Rationalization Prevention

| Excuse                                  | Reality                   |
| --------------------------------------- | ------------------------- |
| "Should work now"                       | RUN the verification      |
| "I'm confident"                         | Confidence ≠ evidence     |
| "Just this once"                        | No exceptions             |
| "Linter passed"                         | Linter ≠ compiler ≠ tests |
| "Agent said success"                    | Verify independently      |
| "Partial check is enough"               | Partial proves nothing    |
| "Different words so rule doesn't apply" | Spirit over letter        |

---

## Verification Patterns

**Tests:**

```
✅ [Run test command] [See: 34/34 pass] "All tests pass"
❌ "Should pass now" / "Looks correct"
```

**Build:**

```
✅ [Run build] [See: exit 0] "Build passes"
❌ "Linter passed" (linter doesn't check compilation)
```

**Requirements:**

```
✅ Re-read plan → Create checklist → Verify each → Report gaps or completion
❌ "Tests pass, phase complete"
```

**Agent delegation:**

```
✅ Agent reports success → Check VCS diff → Verify changes → Report actual state
❌ Trust agent report
```

---

## When to Apply

**ALWAYS before:**

- ANY variation of success/completion claims
- ANY expression of satisfaction
- Committing, PR creation, task completion
- Moving to next task
- Delegating to agents

---

## The Bottom Line

**No shortcuts for verification.**

Run the command. Read the output. THEN claim the result.

This is non-negotiable.

## AGI Framework Integration

### Qdrant Memory Integration

Before executing complex tasks with this skill:
```bash
python3 execution/memory_manager.py auto --query "<task summary>"
```

**Decision Tree:**
- **Cache hit?** Use cached response directly — no need to re-process.
- **Memory match?** Inject `context_chunks` into your reasoning.
- **No match?** Proceed normally, then store results:

```bash
python3 execution/memory_manager.py store \
  --content "Description of what was decided/solved" \
  --type decision \
  --tags verification-before-completion <relevant-tags>
```

> **Note:** Storing automatically updates both Vector (Qdrant) and Keyword (BM25) indices.

### Agent Team Collaboration

- **Strategy**: This skill communicates via the shared memory system.
- **Orchestration**: Invoked by `orchestrator` via intelligent routing.
- **Context Sharing**: Always read previous agent outputs from memory before starting.

### Local LLM Support

When available, use local Ollama models for embedding and lightweight inference:
- Embeddings: `nomic-embed-text` via Qdrant memory system
- Lightweight analysis: Local models reduce API costs for repetitive patterns
